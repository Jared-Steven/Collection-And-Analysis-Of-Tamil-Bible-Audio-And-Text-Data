{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyZcovI5m4kfLexG2LGZww",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jared-Steven/Collection-And-Analysis-Of-Tamil-Bible-Audio-And-Text-Data/blob/main/Collection_And_Analysis_Of_Tamil_Bible_Audio_And_Text_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download The Necessary Libraries"
      ],
      "metadata": {
        "id": "8l1fKK2KweWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!pip install transformers\n",
        "!pip install rippletagger\n",
        "!pip install polyglot\n",
        "!pip install indicnlp\n",
        "!pip install inltk\n",
        "!pip install indic-nlp-library\n",
        "!pip install collections\n",
        "!pip install stanfordnlp\n",
        "!pip install --upgrade collections\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git"
      ],
      "metadata": {
        "id": "aRZ9pwCRweBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import The Necessary Libraries"
      ],
      "metadata": {
        "id": "QaP3KUDfpBfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import wave\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import fft, fftfreq\n",
        "from scipy.signal import spectrogram, welch\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "from indicnlp import common\n",
        "from indicnlp import loader\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.tokenize import sentence_tokenize\n",
        "import sys\n",
        "from indicnlp import common\n",
        "import json\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "8OicOGnYo9tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The below code is used to download the audio file of the Tamil Bible for all the books and its chapters from the website that you've provided through an open API End-Point on each of the Book's page."
      ],
      "metadata": {
        "id": "JUXadhNQo1eQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6zNm_BbvoSq"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/drive/MyDrive/bibaudio/Books') # Create A New folder to save the collected audio\n",
        "url = \"https://live.bible.is/bible/TAMWTC/MAT/1\" # URL Of the Site to scrape the Name of the books and it's chapters\n",
        "#rq_no = 1\n",
        "request_result=requests.get(url)\n",
        "time.sleep(10)\n",
        "soup = BeautifulSoup(request_result.text, \"html.parser\")\n",
        "\n",
        "s = soup.find('script', id='__NEXT_DATA__', type='application/json')\n",
        "s_1 = s.text.strip()\n",
        "data = json.loads(s_1)\n",
        "data_1 = data['props']['pageProps']\n",
        "books = data_1['books']\n",
        "\n",
        "for i in range(len(books)):\n",
        "  bookid = books[i]['book_id']\n",
        "  chapters = books[i]['chapters']\n",
        "  print('book_id: ', bookid)\n",
        "  print('chapter: ', chapters)\n",
        "  bknm_dir = f'/content/drive/MyDrive/bibaudio/Books/{bookid}' # Create A New folder for the seperate books of the new testament within the books folder to save the collected audio\n",
        "  os.mkdir(bknm_dir)\n",
        "  for j in range(len(chapters)):\n",
        "    api_url = f\"https://dbt.io/api/bibles/filesets/TCVWTCN2DA?key=a06351bd-4cae-40e7-90ec-ffdd13506987&v=4&book_id={bookid}&chapter_id={chapters[j]}&type=audio_drama\"\n",
        "\n",
        "    try:\n",
        "        # Make a GET request to the API\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        time.sleep(5)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx and 5xx)\n",
        "\n",
        "        # Parse the JSON response\n",
        "        data = response.json()\n",
        "\n",
        "        # Convert the JSON data to a string\n",
        "        data_string = json.dumps(data)\n",
        "\n",
        "        print(data_string)\n",
        "\n",
        "        audlink = data['data'][0]['path']\n",
        "\n",
        "        print('Link to the audio file', audlink)\n",
        "\n",
        "        download_aud = requests.get(audlink)\n",
        "\n",
        "        file_name = bknm_dir + f'/{bookid} - {chapters[j]}' + '.mp3'\n",
        "\n",
        "        with open(file_name, 'wb') as file:\n",
        "            file.write(download_aud.content)\n",
        "            print(f'{file_name} is saved in the drive')\n",
        "\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The below Code is used to Scrape the text version of the Tamil bible"
      ],
      "metadata": {
        "id": "DIkaFanYo0RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/drive/MyDrive/bibaudio/Books_Text')\n",
        "url = \"https://live.bible.is/bible/TAMWTC/MAT/1\"\n",
        "\n",
        "request_result=requests.get(url)\n",
        "time.sleep(10)\n",
        "soup = BeautifulSoup(request_result.text, \"html.parser\")\n",
        "\n",
        "s = soup.find('script', id='__NEXT_DATA__', type='application/json')\n",
        "s_1 = s.text.strip()\n",
        "data = json.loads(s_1)\n",
        "data_1 = data['props']['pageProps']\n",
        "books = data_1['books']\n",
        "\n",
        "for i in range(len(books)):\n",
        "  bookid = books[i]['book_id']\n",
        "  chapters = books[i]['chapters']\n",
        "  print('book_id: ', bookid)\n",
        "  print('chapter: ', chapters)\n",
        "  bknm_dir = f'/content/drive/MyDrive/bibaudio/Books_Text/{bookid}'\n",
        "  os.mkdir(bknm_dir)\n",
        "  for j in range(len(chapters)):\n",
        "    urls = f'https://live.bible.is/bible/TAMWTC/{bookid}/{chapters[j]}'\n",
        "    max_attempts = 20\n",
        "    for attempt in range(max_attempts):\n",
        "        time.sleep(5)\n",
        "        request_result=requests.get(urls)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(request_result.text, \"html.parser\")\n",
        "\n",
        "        s = soup.find('script', id='__NEXT_DATA__', type='application/json')\n",
        "        if s:\n",
        "            s_1 = s.text.strip()\n",
        "            data = json.loads(s_1)\n",
        "            data_1 = data['props']['pageProps']\n",
        "            current_chap = []\n",
        "\n",
        "            try:\n",
        "              chap = data_1['chapterText']\n",
        "              current_chap.append(chap)\n",
        "              bookid = current_chap[0][0]['book_id']\n",
        "              book_nm = current_chap[0][0]['book_name']\n",
        "              tamil_book_nm = current_chap[0][0]['book_name_alt']\n",
        "              verse_no = current_chap[0][0]['verse_start_alt']\n",
        "              verse_txt = current_chap[0][0]['verse_text']\n",
        "              print(f'Bible Verses from {urls}: ')\n",
        "              print('----- ------')\n",
        "              print('bookid: ', bookid)\n",
        "              print('book_nm: ', book_nm)\n",
        "              print('tamil_book_nm: ', tamil_book_nm)\n",
        "              print('--------------------------------------')\n",
        "              print('verses')\n",
        "              print('------')\n",
        "              verses_no = []\n",
        "              verses = []\n",
        "              for k in range (len(current_chap[0])):\n",
        "                  verse_no = current_chap[0][k]['verse_start_alt']\n",
        "                  verse_txt = current_chap[0][k]['verse_text']\n",
        "                  verses_no.append(verse_no)\n",
        "                  verses.append(verse_txt)\n",
        "                  output_file_path = bknm_dir + f\"/{bookid} - {chapters[j]}\" + \".txt\"\n",
        "              with open(output_file_path, \"w\") as file: #Write the data on the lists verses_no and verses into a text file\n",
        "                  # Iterate through each element in the list\n",
        "                  for v_n, vrs in zip(verses_no, verses):\n",
        "                      # Remove any newline characters from the string\n",
        "                      ent_verse = v_n + \" \" + vrs\n",
        "                      cleaned_item = ent_verse.replace(\"\\n\", \"\")\n",
        "                      # Write the cleaned string to the file with a newline character at the end\n",
        "                      file.write(cleaned_item + \"\\n\")\n",
        "\n",
        "              print('verse_no: ', verses_no)\n",
        "              print('Full Verses: ', verses)\n",
        "              print('--------------------------------------')\n",
        "              break\n",
        "            except:\n",
        "              print(f'Attempt {attempt} failed for the chapter url {urls}')\n",
        "\n",
        "        else:\n",
        "          time.sleep(5)\n",
        "          break"
      ],
      "metadata": {
        "id": "6k6mJhPhotZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n"
      ],
      "metadata": {
        "id": "pqXUl5bHp5lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/drive/MyDrive/bibaudio/books_in_WAV') # Create A New folder to save the collected audio"
      ],
      "metadata": {
        "id": "14NlOeQep7QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_mp3_to_wav(source_dir, target_dir):\n",
        "    # Walk through the source directory\n",
        "    for root, dirs, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.mp3'):\n",
        "                # Construct full file paths\n",
        "                source_file_path = os.path.join(root, file)\n",
        "                relative_path = os.path.relpath(root, source_dir)\n",
        "                target_file_dir = os.path.join(target_dir, relative_path)\n",
        "                target_file_path = os.path.join(target_file_dir, file[:-4] + '.wav')\n",
        "\n",
        "                # Ensure the target directory exists\n",
        "                os.makedirs(target_file_dir, exist_ok=True)\n",
        "\n",
        "                # Load the MP3 file\n",
        "                audio = AudioSegment.from_mp3(source_file_path)\n",
        "\n",
        "                # Export as WAV file\n",
        "                audio.export(target_file_path, format='wav')\n",
        "\n",
        "                print(f'Converted: {source_file_path} to {target_file_path}')\n",
        "\n",
        "# Example usage\n",
        "source_directory = '/content/drive/MyDrive/bibaudio/Books'\n",
        "target_directory = '/content/drive/MyDrive/bibaudio/books_in_WAV'\n",
        "\n",
        "convert_mp3_to_wav(source_directory, target_directory)\n"
      ],
      "metadata": {
        "id": "h2vBB-NfqCWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping the text data with the audio data and saving it on a dictionary for quick access if needed."
      ],
      "metadata": {
        "id": "B1-oY291qGSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def find_wav_and_text_files(directory):\n",
        "    wav_files = []\n",
        "    text_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                wav_files.append(os.path.join(root, file))\n",
        "            elif file.endswith('.txt'):\n",
        "                text_files.append(os.path.join(root, file))\n",
        "\n",
        "    return wav_files, text_files\n",
        "\n",
        "def map_text_to_wav(directory1, directory2):\n",
        "    wav_files1, text_files1 = find_wav_and_text_files(directory1)\n",
        "    wav_files2, text_files2 = find_wav_and_text_files(directory2)\n",
        "\n",
        "    wav_files = wav_files1 + wav_files2\n",
        "    text_files = text_files1 + text_files2\n",
        "\n",
        "    # Create a dictionary to map text files to wav files\n",
        "    text_to_wav_mapping = {}\n",
        "\n",
        "    for text_file in text_files:\n",
        "        # Find the corresponding wav file\n",
        "        base_name = os.path.splitext(os.path.basename(text_file))[0]\n",
        "        corresponding_wav_file = next((wav_file for wav_file in wav_files if base_name in wav_file), None)\n",
        "\n",
        "        if corresponding_wav_file:\n",
        "            text_to_wav_mapping[text_file] = corresponding_wav_file\n",
        "\n",
        "    return text_to_wav_mapping\n",
        "\n",
        "# Example usage\n",
        "directory1 = '/content/drive/MyDrive/bibaudio/Books_Text'\n",
        "directory2 = '/content/drive/MyDrive/bibaudio/books_in_WAV'\n",
        "\n",
        "mapping = map_text_to_wav(directory1, directory2)\n",
        "\n",
        "\n",
        "# Print the mapping\n",
        "for text_file, wav_file in mapping.items():\n",
        "    print(f'Text File: {text_file} -> WAV File: {wav_file}')\n"
      ],
      "metadata": {
        "id": "AquLpTVRqHwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "uxY-2z2PwCmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Analysis"
      ],
      "metadata": {
        "id": "RIhRtVbUwD0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing NLP tasks such as tokenization, part-of-speech tagging, named entity recognition, and sentiment analysis on the text data."
      ],
      "metadata": {
        "id": "2CF7yIcwwHkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=r\"indic_nlp_resources\"\n",
        "\n",
        "# Add library to Python path\n",
        "sys.path.append(r'{}\\src'.format(INDIC_NLP_LIB_HOME))\n",
        "\n",
        "# Set environment variable for resources folder\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "metadata": {
        "id": "ASxaNrfdwMle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure required resources are downloaded\n",
        "nltk.download('punkt')\n",
        "#spacy.cli.download(\"ta_core_news_sm\")\n",
        "\n",
        "# Function to read Tamil text file\n",
        "def read_tamil_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "file_path = '/content/drive/MyDrive/bibaudio/Books_Text/MAT/MAT - 1.txt'\n",
        "tamil_text = read_tamil_text(file_path)\n",
        "\n",
        "# Tokenization\n",
        "indic_string = tamil_text\n",
        "#print('Input String: {}'.format(indic_string))\n",
        "print('Tokens: ')\n",
        "for t in indic_tokenize.trivial_tokenize(indic_string):\n",
        "        print(t)\n",
        "\n"
      ],
      "metadata": {
        "id": "_0TdsOsxw35f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the text file for reading\n",
        "with open('/content/drive/MyDrive/bibaudio/Books_Text/MAT/MAT - 1.txt', 'r') as file:\n",
        "    # Read all lines from the text file\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Create a list to store the rows\n",
        "rows = []\n",
        "\n",
        "# Iterate over the lines\n",
        "for line in lines:\n",
        "    # Remove the newline character and split the line into values\n",
        "    values = line.strip().split(',')\n",
        "    rows.append(values)\n",
        "\n",
        "# Open a new CSV file for writing\n",
        "with open('output_file.csv', 'w', newline='') as file:\n",
        "    import csv\n",
        "    # Create a CSV writer object\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write each row to the CSV file\n",
        "    for row in rows:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(\"Text file converted to CSV successfully!\")"
      ],
      "metadata": {
        "id": "PDnqAZZFw689"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('/content/output_file.csv', header=0, sep='\\t')"
      ],
      "metadata": {
        "id": "pYiSr6t3w6vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign a new column name to the first column\n",
        "df.columns = [0] + [None] * (df.shape[1] - 1)  # Assign a name to the first column and keep others as None\n",
        "df.rename(columns={0: 'verses'}, inplace=True)\n",
        "\n",
        "# Print the column names\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "DS5VCcT-w6iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first few rows of the DataFrame\n",
        "print(df['verses'].head())"
      ],
      "metadata": {
        "id": "dSjYlD0OxMsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "# Checking information of the data"
      ],
      "metadata": {
        "id": "5hQU8WzzxMcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "# Describe function shows us the frequency,unique and counts of all columns"
      ],
      "metadata": {
        "id": "rpPEgA-uxMNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()\n",
        "# nunique() function return number of unique elements in the object."
      ],
      "metadata": {
        "id": "zlW9nqjfxMBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Analysis"
      ],
      "metadata": {
        "id": "WpediD-nz3nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the WAV file\n",
        "file_path = '/content/drive/MyDrive/bibaudio/books_in_WAV/MAT/MAT - 1.wav'\n",
        "wav_file = wave.open(file_path, 'r')\n",
        "\n",
        "# Extract basic information\n",
        "n_channels = wav_file.getnchannels()\n",
        "sample_width = wav_file.getsampwidth()\n",
        "frame_rate = wav_file.getframerate()\n",
        "n_frames = wav_file.getnframes()\n",
        "duration = n_frames / frame_rate\n",
        "\n",
        "print(f'Number of channels: {n_channels}')\n",
        "print(f'Sample width (bytes): {sample_width}')\n",
        "print(f'Frame rate (samples per second): {frame_rate}')\n",
        "print(f'Number of frames: {n_frames}')\n",
        "print(f'Duration (seconds): {duration:.2f}')\n",
        "\n",
        "# Read frames and convert to numpy array\n",
        "audio_frames = wav_file.readframes(n_frames)\n",
        "audio_data = np.frombuffer(audio_frames, dtype=np.int16)\n",
        "wav_file.close()\n",
        "\n",
        "# If stereo, take only one channel for simplicity\n",
        "if n_channels == 2:\n",
        "    audio_data = audio_data[::2]\n",
        "\n",
        "# Create time axis\n",
        "time_axis = np.linspace(0, duration, num=len(audio_data))\n",
        "\n",
        "# Plot the waveform\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(time_axis, audio_data)\n",
        "plt.title('Waveform')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "# Perform FFT\n",
        "fft_data = fft(audio_data)\n",
        "fft_magnitude = np.abs(fft_data)\n",
        "frequencies = fftfreq(len(audio_data), 1/frame_rate)\n",
        "\n",
        "# Plot the FFT results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(frequencies[:len(frequencies)//2], fft_magnitude[:len(frequencies)//2])\n",
        "plt.title('Frequency Analysis')\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Magnitude')\n",
        "plt.show()\n",
        "\n",
        "# Plot the spectrogram\n",
        "frequencies_spec, times_spec, Sxx = spectrogram(audio_data, frame_rate)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.pcolormesh(times_spec, frequencies_spec, 10 * np.log10(Sxx), shading='gouraud')\n",
        "plt.title('Spectrogram')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.colorbar(label='Intensity (dB)')\n",
        "plt.show()\n",
        "\n",
        "# Plot Power Spectral Density (PSD)\n",
        "frequencies_psd, psd = welch(audio_data, frame_rate, nperseg=1024)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.semilogy(frequencies_psd, psd)\n",
        "plt.title('Power Spectral Density')\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power/Frequency (dB/Hz)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PTNwJYcqxLuN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}